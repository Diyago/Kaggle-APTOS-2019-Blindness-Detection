model_params:
  model: efficientnet_pretrained
  k: 5
  num_classes: 1
  pretrained: True

distributed_params:
  opt_level: O1

args:
  expdir: "src"
  logdir: &logdir "./logs/efficientnet-5/finetuning_456_color=0.35_scale=0.35_0.75"

stages:

  data_params:
    batch_size: 8
    num_workers: 12
    in_csv: "./data/train.csv"
    class_column: "diagnosis"
    input_column: "id_code"
    train_folds: [0, 1, 2, 3, 4]
    valid_folds: [4]
    datapath: "./data/train_images"
    image_size: 456
    upsampling: False
    crop_from_gray: True
    circle_crop: True
    normalize: True
    ben_preprocess: 10
    hor_flip: 0.5
    ver_flip: 0.3
    rotate: 360
    random_scale: 0.3
    random_scale_p: 0.75
    brightness: 0.35
    contrast: 0.35

#  state_params:
#    num_epochs: &num_epochs 5
#    main_metric: &reduce_metric kappa_score
#    minimize_metric: False

  criterion_params:
    criterion: MSELoss

  stage1:

    state_params:
      num_epochs: &num_epochs 5
      main_metric: &reduce_metric kappa_score
      minimize_metric: False

    optimizer_params:
      optimizer: Adam
      lr: 0.0001
      weight_decay: 0.000001

    scheduler_params:
      scheduler: MultiStepLR
      milestones: [2, 3]
      gamma: 0.1
      #scheduler: OneCycleLR
      #num_steps: *num_epochs
      #lr_range: [0.0001, 0.00004]
      #init_lr: 0.0004
      #warmup_fraction: 0.2

    callbacks_params:
      loss:
        callback: CriterionCallback
      optimizer:
        callback: OptimizerCallback
      scheduler:
        callback: SchedulerCallback
        reduce_metric: *reduce_metric
      saver:
        callback: CheckpointCallback
        resume: "./logs/efficientnet-5/456_pretraining_old_data/checkpoints/stage1.13.pth"
      kappa:
        callback: KappaCallback
        num_classes: 5