{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "package_path = '../EfficientNet-PyTorch/'\n",
    "sys.path.append(package_path)\n",
    "\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from radam import RAdam, PlainRAdam, AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transforms import (pre_transforms, post_transforms, my_transforms, Compose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import time \n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as D\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms as T\n",
    "from torch.optim.lr_scheduler import ExponentialLR, StepLR, ReduceLROnPlateau, CosineAnnealingLR\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "from ignite.engine import Events, create_supervised_evaluator, create_supervised_trainer\n",
    "from ignite.metrics import Loss, Accuracy\n",
    "from ignite.contrib.handlers.tqdm_logger import ProgressBar\n",
    "from ignite.handlers import  EarlyStopping, ModelCheckpoint\n",
    "\n",
    "import albumentations\n",
    "from albumentations import torch as AT\n",
    "\n",
    "#from am_softmax import AMSoftmaxLoss, AngleSimpleLinear\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'SEED': 42,\n",
    "    'CLASSES': 1,\n",
    "    'PATH_DATA': '',\n",
    "    'PRETRAIN_PATH_DATA': 'pretrain_2015_data',\n",
    "    'DEVICE': 'cuda',\n",
    "    'BATCH_SIZE': 8,\n",
    "    'VAL_SIZE': 0.1,\n",
    "    'MODEL_NAME': 'EffNet_b3_Adam_regr',\n",
    "    'USE_ANGULAR': False,\n",
    "    'USE_BN': False,\n",
    "    'LR': 1e-4,\n",
    "    'TURN_OFF_ON_N_EPOCHS': 0,\n",
    "}\n",
    "\n",
    "image_size = 256\n",
    "upsampling = True\n",
    "crop_from_gray = True\n",
    "circle_crop = True\n",
    "normalize = True\n",
    "ben_preprocess = 10\n",
    "hor_flip = 0.5\n",
    "ver_flip = 0.33\n",
    "rotate = 360\n",
    "random_scale = 0.35\n",
    "random_scale_p = 0.75\n",
    "brightness = 0.35\n",
    "contrast = 0.35\n",
    "color_p = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_torch(seed=42):\n",
    "    import random; import os\n",
    "\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed_torch(config['SEED'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def argmax_predictions(predictions):\n",
    "    coef = [0.57, 1.57, 2.57, 3.57]\n",
    "\n",
    "    for i, pred in enumerate(predictions):\n",
    "        if pred < coef[0]:\n",
    "            predictions[i] = 0\n",
    "        elif pred >= coef[0] and pred < coef[1]:\n",
    "            predictions[i] = 1\n",
    "        elif pred >= coef[1] and pred < coef[2]:\n",
    "            predictions[i] = 2\n",
    "        elif pred >= coef[2] and pred < coef[3]:\n",
    "            predictions[i] = 3\n",
    "        else:\n",
    "            predictions[i] = 4\n",
    "            \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EffNet(nn.Module):\n",
    "    def __init__(self, num_classes=1000, num_channels=3, use_angular=False, use_bn=False):\n",
    "        super().__init__()\n",
    "        self.use_angular = use_angular\n",
    "        self.use_bn = use_bn\n",
    "        self.bn = nn.BatchNorm2d(num_channels)\n",
    "        \n",
    "        self.features = EfficientNet.from_pretrained('efficientnet-b3', num_classes=num_classes)\n",
    "        #print(self.features)\n",
    "        \n",
    "        if self.use_angular:\n",
    "            self.features._fc = AngleSimpleLinear(1280, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if self.use_bn:\n",
    "            x = self.bn(x)\n",
    "            \n",
    "        out = self.features(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PreTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain = pd.read_csv(config['PRETRAIN_PATH_DATA']+'/trainLabels.csv')\n",
    "pretrain_cropped = pd.read_csv(config['PRETRAIN_PATH_DATA']+'/trainLabels_cropped.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35126, 35108)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pretrain), len(pretrain_cropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreTrainGlassDataset(D.Dataset):\n",
    "    def __init__(self, df, transform=T.Compose([T.CenterCrop(32), T.ToTensor()]), y=None):\n",
    "        self.df = df\n",
    "        self.image_files_list = [config['PRETRAIN_PATH_DATA'] + f'/resized_train/{i}.jpeg' for i in df['image'].values]\n",
    "        self.labels = y            \n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.image_files_list[idx]\n",
    "        image = cv2.imread(img_name)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        final = self.transform(image=image)\n",
    "        final = final['image']\n",
    "        \n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        return final, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_transform_fn = pre_transforms(image_size=image_size, \n",
    "                                  crop_from_gray=crop_from_gray, \n",
    "                                  circle_crop=circle_crop,\n",
    "                                  ben_preprocess=ben_preprocess,\n",
    "                                  random_scale=random_scale, \n",
    "                                  random_scale_p=random_scale_p,\n",
    "                                  brightness=brightness,\n",
    "                                  contrast=contrast,\n",
    "                                  color_p=color_p\n",
    "                                  )\n",
    "\n",
    "my_transform_fn = my_transforms(hor_flip=hor_flip,\n",
    "                                ver_flip=ver_flip,\n",
    "                                rotate=rotate)\n",
    "\n",
    "post_transform_fn = post_transforms(normalize=normalize)\n",
    "\n",
    "data_transforms = Compose([pre_transform_fn, my_transform_fn, post_transform_fn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = PreTrainGlassDataset(df=pretrain, transform=data_transforms, y=pretrain.level)\n",
    "\n",
    "tr, val = train_test_split(pretrain.level, stratify=pretrain.level,\n",
    "                           test_size=config['VAL_SIZE'], random_state=config['SEED'])\n",
    "train_sampler = SubsetRandomSampler(list(tr.index))\n",
    "valid_sampler = SubsetRandomSampler(list(val.index))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=config['BATCH_SIZE'],\n",
    "                                           sampler=train_sampler, num_workers=4)\n",
    "valid_loader = torch.utils.data.DataLoader(dataset, batch_size=config['BATCH_SIZE'],\n",
    "                                           sampler=valid_sampler, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b3\n"
     ]
    }
   ],
   "source": [
    "model = EffNet(num_classes=config['CLASSES'], use_angular=False, use_bn=False)\n",
    "model.to(config['DEVICE']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fca5be6ad4c146e0a89c67e5a3d4a8d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3952), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1, train loss: 0.9533, valid loss: 0.9419 \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "254b2f5d0ed04b57bb342f46e92135f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3952), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2, train loss: 0.9482, valid loss: 0.9444 \n",
      "1 epochs of increasing val loss\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a5da3928c184832a42b38a38963fe72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3952), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3, train loss: 0.9460, valid loss: 0.9403 \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7b0d644aac843eeac5a0e48bac0def3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3952), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4, train loss: 0.9456, valid loss: 0.9520 \n",
      "1 epochs of increasing val loss\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da1ef714c8814f91ad48646e443e45f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3952), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5, train loss: 0.9454, valid loss: 0.9412 \n",
      "2 epochs of increasing val loss\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5be6ca8fcdbe444d982b0060d16d28ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3952), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6, train loss: 0.9450, valid loss: 0.9410 \n",
      "3 epochs of increasing val loss\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95c102b1b3914fa48d8b7204aac1a9e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3952), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7, train loss: 0.9442, valid loss: 0.9425 \n",
      "4 epochs of increasing val loss\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b615310f3bbe491ea9ea3f2af5328c2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3952), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-87e4ca4e76ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# train_auc.append(roc_auc_score(a, b))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/nikita_tensorflow/lib/python3.7/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     99\u001b[0m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_exp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                 \u001b[0mbias_correction1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'step'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "valid_loss_min = np.Inf\n",
    "patience = 5\n",
    "\n",
    "# current number of epochs, where validation loss didn't increase\n",
    "p = 0\n",
    "# whether training should be stopped\n",
    "stop = False\n",
    "\n",
    "# number of epochs to train the model\n",
    "n_epochs = 20\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    \n",
    "    model.train()\n",
    "    train_loss = []\n",
    "    train_auc = []\n",
    "    for (data, target) in tqdm_notebook(train_loader):\n",
    "\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target.float())\n",
    "        train_loss.append(loss.item())\n",
    "        \n",
    "        a = target.data.cpu().numpy()\n",
    "        b = output[:,-1].detach().cpu().numpy()\n",
    "        # train_auc.append(roc_auc_score(a, b))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    model.eval()\n",
    "    val_loss = []\n",
    "    val_auc = []\n",
    "    for (data, target) in (valid_loader):\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "        output = model(data)\n",
    "\n",
    "        loss = criterion(output, target.float())\n",
    "\n",
    "        val_loss.append(loss.item()) \n",
    "        a = target.data.cpu().numpy()\n",
    "        b = output[:,-1].detach().cpu().numpy()\n",
    "        # val_auc.append(roc_auc_score(a, b))\n",
    "\n",
    "    # print(f'Epoch {epoch}, train loss: {np.mean(train_loss):.4f}, valid loss: {np.mean(val_loss):.4f}, train auc: {np.mean(train_auc):.4f}, valid auc: {np.mean(val_auc):.4f}')\n",
    "    print(f'Epoch {epoch}, train loss: {np.mean(train_loss):.4f}, valid loss: {np.mean(val_loss):.4f} ')\n",
    "    \n",
    "    valid_loss = np.mean(val_loss)\n",
    "    # scheduler.step(valid_loss)\n",
    "    if valid_loss <= valid_loss_min:\n",
    "        torch.save(model.state_dict(), '{0}/{0}_{1}_pretrain.pt'.format(config['MODEL_NAME'], epoch))\n",
    "        valid_loss_min = valid_loss\n",
    "        p = 0\n",
    "\n",
    "    # check if validation loss didn't improve\n",
    "    if valid_loss > valid_loss_min:\n",
    "        p += 1\n",
    "        print(f'{p} epochs of increasing val loss')\n",
    "        if p > patience:\n",
    "            print('Stopping training')\n",
    "            stop = True\n",
    "            break        \n",
    "            \n",
    "    if stop:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'SEED': 42,\n",
    "    'CLASSES': 1,\n",
    "    'PATH_DATA': '',\n",
    "    'PRETRAIN_PATH_DATA': 'pretrain_2015_data',\n",
    "    'DEVICE': 'cuda',\n",
    "    'BATCH_SIZE': 8,\n",
    "    'VAL_SIZE': 0.1,\n",
    "    'MODEL_NAME': 'EffNet_b3_Adam_regr',\n",
    "    'USE_ANGULAR': False,\n",
    "    'USE_BN': False,\n",
    "    'LR': 1e-4,\n",
    "    'TURN_OFF_ON_N_EPOCHS': 0,\n",
    "}\n",
    "\n",
    "image_size = 256\n",
    "upsampling = False\n",
    "crop_from_gray = True\n",
    "circle_crop = True\n",
    "normalize = True\n",
    "ben_preprocess = 10\n",
    "hor_flip = 0.5\n",
    "ver_flip = 0.33\n",
    "rotate = 360\n",
    "random_scale = 0.35\n",
    "random_scale_p = 0.75\n",
    "brightness = 0.35\n",
    "contrast = 0.35\n",
    "color_p = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(config['PATH_DATA']+'train.csv')\n",
    "test = pd.read_csv(config['PATH_DATA']+'test.csv')\n",
    "sample_submission = pd.read_csv(config['PATH_DATA']+'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3662, 1928)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train), len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GlassDataset(D.Dataset):\n",
    "    def __init__(self, df, datatype='train',\n",
    "                 transform=T.Compose([T.CenterCrop(32), T.ToTensor()]), y=None):\n",
    "        self.df = df\n",
    "        self.datatype = datatype\n",
    "        self.image_files_list = [f'{self.datatype}_images/{i}.png' for i in df['id_code'].values]\n",
    "        \n",
    "        if self.datatype == 'train':\n",
    "            self.labels = y\n",
    "        else:\n",
    "            self.labels = np.zeros((df.shape[0], 1))\n",
    "            \n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.image_files_list[idx]\n",
    "        image = cv2.imread(img_name)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        final = self.transform(image=image)\n",
    "        final = final['image']\n",
    "        \n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        return final, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_transform_fn = pre_transforms(image_size=image_size, \n",
    "                                  crop_from_gray=crop_from_gray, \n",
    "                                  circle_crop=circle_crop,\n",
    "                                  ben_preprocess=ben_preprocess,\n",
    "                                  random_scale=random_scale, \n",
    "                                  random_scale_p=random_scale_p,\n",
    "                                  brightness=brightness,\n",
    "                                  contrast=contrast,\n",
    "                                  color_p=color_p\n",
    "                                  )\n",
    "\n",
    "my_transform_fn = my_transforms(hor_flip=hor_flip,\n",
    "                                ver_flip=ver_flip,\n",
    "                                rotate=rotate)\n",
    "\n",
    "post_transform_fn = post_transforms(normalize=normalize)\n",
    "\n",
    "data_transforms = Compose([pre_transform_fn, my_transform_fn, post_transform_fn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = GlassDataset(df=train, datatype='train', transform=data_transforms, y=train.diagnosis)\n",
    "#test_set = GlassDataset(df=test, datatype='test', transform=data_transforms_test)\n",
    "\n",
    "tr, val = train_test_split(train.diagnosis, stratify=train.diagnosis,\n",
    "                           test_size=config['VAL_SIZE'], random_state=config['SEED'])\n",
    "train_sampler = SubsetRandomSampler(list(tr.index))\n",
    "valid_sampler = SubsetRandomSampler(list(val.index))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=config['BATCH_SIZE'],\n",
    "                                           sampler=train_sampler, num_workers=4)\n",
    "valid_loader = torch.utils.data.DataLoader(dataset, batch_size=config['BATCH_SIZE'],\n",
    "                                           sampler=valid_sampler, num_workers=4)\n",
    "#test_loader = torch.utils.data.DataLoader(test_set, batch_size=config['BATCH_SIZE'],\n",
    "#                                          num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b3\n"
     ]
    }
   ],
   "source": [
    "model = EffNet(num_classes=config['CLASSES'], use_angular=False)\n",
    "model.load_state_dict(torch.load('{0}/{0}_3_pretrain.pt'.format('EffNet_b3_Adam_regr')))\n",
    "model.to(config['DEVICE']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for name, child in model.named_children():\n",
    "#    if name == 'bn':\n",
    "#        print(name + ' is unfrozen')\n",
    "#        for param in child.parameters():\n",
    "#            param.requires_grad = True\n",
    "            \n",
    "#    else:\n",
    "#        for child_name, child_2 in child.named_children():\n",
    "#            if child_name == '_fc':\n",
    "#                print(child_name + ' is unfrozen')\n",
    "#                for param in child_2.parameters():\n",
    "#                    param.requires_grad = True\n",
    "#            else:\n",
    "#                for param in child_2.parameters():\n",
    "#                    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#criterion = nn.CrossEntropyLoss()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "#scheduler = StepLR(optimizer, step_size=2, gamma=0.1)\n",
    "#optimizer = optim.SGD(model.parameters(), lr=3e-2, momentum=0.95)\n",
    "#scheduler = CyclicLR(optimizer, base_lr=lr, max_lr=0.01, step_size=5, mode='triangular2')\n",
    "#scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.8, patience=2, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3664a44e243f4527a1cdb8b8d98115a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=412), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1, train loss: 1.7047, valid loss: 1.7397 \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f0f087beeaa41b08c1e58d59406e393",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=412), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2, train loss: 1.6958, valid loss: 1.6964 \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8206679dafc34ba29b995944fd504d7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=412), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3, train loss: 1.6988, valid loss: 1.7150 \n",
      "1 epochs of increasing val loss\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f09297797b04387827d6d8c2c458963",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=412), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4, train loss: 1.6979, valid loss: 1.7180 \n",
      "2 epochs of increasing val loss\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1523202238984ab2b8f1e507351970c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=412), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5, train loss: 1.6951, valid loss: 1.7213 \n",
      "3 epochs of increasing val loss\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8642dd2cf06e4321925b36336e915e18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=412), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6, train loss: 1.6967, valid loss: 1.6929 \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d184eaba52a41fca3aec2c01827a569",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=412), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7, train loss: 1.6905, valid loss: 1.6958 \n",
      "1 epochs of increasing val loss\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a075a021432d4234b399f6b6873287a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=412), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8, train loss: 1.6955, valid loss: 1.6971 \n",
      "2 epochs of increasing val loss\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78aab66a08e648f58168efd51002e57d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=412), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9, train loss: 1.6977, valid loss: 1.6975 \n",
      "3 epochs of increasing val loss\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "196dec5663a34b3ea23769a4b5ead1db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=412), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10, train loss: 1.6962, valid loss: 1.7044 \n",
      "4 epochs of increasing val loss\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc806e492b7542baaccdb5fb4f5e106c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=412), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 11, train loss: 1.6986, valid loss: 1.7070 \n",
      "5 epochs of increasing val loss\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00ba6d5cad9748b5aa2dcd7a2a312dda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=412), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 12, train loss: 1.6914, valid loss: 1.6945 \n",
      "6 epochs of increasing val loss\n",
      "Stopping training\n"
     ]
    }
   ],
   "source": [
    "valid_loss_min = np.Inf\n",
    "patience = 5\n",
    "\n",
    "# current number of epochs, where validation loss didn't increase\n",
    "p = 0\n",
    "# whether training should be stopped\n",
    "stop = False\n",
    "\n",
    "# number of epochs to train the model\n",
    "n_epochs = 20\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    \n",
    "    model.train()\n",
    "    train_loss = []\n",
    "    train_auc = []\n",
    "    for (data, target) in tqdm_notebook(train_loader):\n",
    "\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target.float())\n",
    "        train_loss.append(loss.item())\n",
    "        \n",
    "        a = target.data.cpu().numpy()\n",
    "        b = output[:,-1].detach().cpu().numpy()\n",
    "        # train_auc.append(roc_auc_score(a, b))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    del data, target, output\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    model.eval()\n",
    "    val_loss = []\n",
    "    val_auc = []\n",
    "    for (data, target) in (valid_loader):\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "        output = model(data)\n",
    "\n",
    "        loss = criterion(output, target.float())\n",
    "\n",
    "        val_loss.append(loss.item()) \n",
    "        a = target.data.cpu().numpy()\n",
    "        b = output[:,-1].detach().cpu().numpy()\n",
    "        # val_auc.append(roc_auc_score(a, b))\n",
    "        \n",
    "    del data, target, output\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # print(f'Epoch {epoch}, train loss: {np.mean(train_loss):.4f}, valid loss: {np.mean(val_loss):.4f}, train auc: {np.mean(train_auc):.4f}, valid auc: {np.mean(val_auc):.4f}')\n",
    "    print(f'Epoch {epoch}, train loss: {np.mean(train_loss):.4f}, valid loss: {np.mean(val_loss):.4f} ')\n",
    "    \n",
    "    valid_loss = np.mean(val_loss)\n",
    "    # scheduler.step(valid_loss)\n",
    "    if valid_loss <= valid_loss_min:\n",
    "        torch.save(model.state_dict(), '{0}/{0}_{1}.pt'.format(config['MODEL_NAME'], epoch))\n",
    "        valid_loss_min = valid_loss\n",
    "        p = 0\n",
    "\n",
    "    # check if validation loss didn't improve\n",
    "    if valid_loss > valid_loss_min:\n",
    "        p += 1\n",
    "        print(f'{p} epochs of increasing val loss')\n",
    "        if p > patience:\n",
    "            print('Stopping training')\n",
    "            stop = True\n",
    "            break        \n",
    "            \n",
    "    if stop:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
